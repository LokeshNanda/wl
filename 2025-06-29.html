<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Sunday, 29 Jun 2025 | Lokesh Nanda - Weekly Notes</title>
  <link href="https://fonts.googleapis.com/css2?family=Georgia:wght@400;700&family=Inter:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pygments/2.16.1/styles/github.min.css">
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      background-color: #ffffff;
      font-family: Georgia, serif;
      font-size: 18px;
      line-height: 1.7;
      color: #2c2c2c;
      max-width: 680px;
      margin: 0 auto;
      padding: 2rem 1.5rem;
    }

    .header {
      text-align: center;
      margin-bottom: 3rem;
      padding-bottom: 2rem;
      border-bottom: 1px solid #e5e5e5;
    }

    .header h1 {
      font-family: Georgia, serif;
      font-size: 2.5rem;
      font-weight: 700;
      color: #1a1a1a;
      margin-bottom: 0.5rem;
      letter-spacing: -0.02em;
    }

    .header .date {
      font-size: 1rem;
      color: #666;
      font-style: italic;
    }

    .note {
      margin-bottom: 2.5rem;
      padding-bottom: 2rem;
      border-bottom: 1px solid #f0f0f0;
    }

    .note:last-child {
      border-bottom: none;
      margin-bottom: 3rem;
    }

    .note p {
      margin-bottom: 1.2rem;
    }

    .note ul, .note ol {
      margin: 1.5rem 0;
      padding-left: 2rem;
    }

    .note li {
      margin-bottom: 0.8rem;
    }

    .note a {
      color: #0066cc;
      text-decoration: underline;
      text-decoration-thickness: 1px;
      text-underline-offset: 2px;
    }

    .note a:hover {
      color: #004499;
    }

    .note code {
      font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Roboto Mono', monospace;
      background: #f8f8f8;
      padding: 0.2em 0.4em;
      border-radius: 3px;
      font-size: 0.9em;
      color: #d73a49;
    }

    .note pre {
      background: #f8f8f8;
      padding: 1.2rem;
      border-radius: 4px;
      overflow-x: auto;
      margin: 1.5rem 0;
      border-left: 3px solid #0066cc;
      font-size: 0.9em;
    }

    .note h2, .note h3, .note h4 {
      font-family: Georgia, serif;
      color: #1a1a1a;
      font-weight: 700;
      margin: 2rem 0 1rem 0;
      line-height: 1.3;
    }

    .note h2 {
      font-size: 1.5em;
    }

    .note h3 {
      font-size: 1.3em;
    }

    .note h4 {
      font-size: 1.1em;
    }

    .note strong, .note b {
      font-weight: 700;
      color: #1a1a1a;
    }

    .note em, .note i {
      font-style: italic;
    }

    .note blockquote {
      border-left: 4px solid #e5e5e5;
      padding-left: 1.5rem;
      margin: 1.5rem 0;
      font-style: italic;
      color: #555;
    }

    nav {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding-top: 2rem;
      border-top: 1px solid #e5e5e5;
      margin-top: 2rem;
      font-family: Inter, sans-serif;
      font-size: 0.9rem;
    }

    nav a {
      color: #0066cc;
      text-decoration: none;
      padding: 0.5rem 0;
      transition: color 0.2s ease;
    }

    nav a:hover {
      color: #004499;
      text-decoration: underline;
    }

    .nav-home {
      font-weight: 500;
    }

    @media (max-width: 768px) {
      body {
        padding: 1.5rem 1rem;
        font-size: 17px;
      }

      .header h1 {
        font-size: 2rem;
      }

      .note ul, .note ol {
        padding-left: 1.5rem;
      }

      nav {
        flex-direction: column;
        gap: 1rem;
        text-align: center;
      }
    }
  </style>
</head>
<body>
  <div class="header">
    <h1>Sunday, 29 Jun 2025</h1>
    <div class="date">Weekly Notes and Findings</div>
  </div>

  
    <div class="note"><ul>
<li>Came across a graph database - <a href="https://docs.hypermode.com/dgraph/overview">DGraph</a></li>
<li>Found it to be very interesting open source project<ul>
<li>Explored its competitor - Neo4j atlas:</li>
<li>Created an account in neo4j atlas online. Self hosting was also an option, but went ahead with this.</li>
<li>created an itegration to extract wiki pages using langgraph and extract entities.
      ```python
          from dotenv import load_dotenv
          import os
          from langchain_neo4j import Neo4jGraph<pre class="codehilite"><code>  from langchain_core.runnables import (
      RunnableBranch,
      RunnableLambda,
      RunnableParallel,
      RunnablePassthrough,
  )
  from langchain_core.prompts import ChatPromptTemplate
  from langchain_core.prompts.prompt import PromptTemplate
  from pydantic import BaseModel, Field
  # from langchain_core.pydantic_v1 import BaseModel, Field
  from typing import Tuple, List
  from langchain_core.messages import AIMessage, HumanMessage
  from langchain_core.output_parsers import StrOutputParser
  from langchain_community.document_loaders import WikipediaLoader
  from langchain.text_splitter import TokenTextSplitter
  from langchain_openai import ChatOpenAI
  from langchain_experimental.graph_transformers import LLMGraphTransformer

  from langchain_neo4j import Neo4jVector
  from langchain_openai import OpenAIEmbeddings
  from langchain_neo4j.vectorstores.neo4j_vector import remove_lucene_chars

  load_dotenv()

  AURA_INSTANCENAME = os.environ[&quot;AURA_INSTANCENAME&quot;]
  NEO4J_URI = os.environ[&quot;NEO4J_URI&quot;]
  NEO4J_USERNAME = os.environ[&quot;NEO4J_USERNAME&quot;]
  NEO4J_PASSWORD = os.environ[&quot;NEO4J_PASSWORD&quot;]
  AUTH = (NEO4J_USERNAME, NEO4J_PASSWORD)

  OPENAI_API_KEY = os.getenv(&quot;OPENAI_API_KEY&quot;)
  OPENAI_ENDPOINT = os.getenv(&quot;OPENAI_ENDPOINT&quot;)

  chat = ChatOpenAI(api_key=OPENAI_API_KEY, temperature=0, model=&quot;gpt-4o-mini&quot;)

  kg = Neo4jGraph(
    url=NEO4J_URI,
    username=NEO4J_USERNAME,
    password=NEO4J_PASSWORD,
  ) #database=NEO4J_DATABASE,

  # # # read the wikipedia page for the Roman Empire
  raw_documents = WikipediaLoader(query=&quot;The Indian Politics&quot;).load()

  # # # # # Define chunking strategy
  text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)
  documents = text_splitter.split_documents(raw_documents[:3])
  print(documents)

  llm_transformer = LLMGraphTransformer(llm=chat)
  graph_documents = llm_transformer.convert_to_graph_documents(documents)

  # store to neo4j
  res = kg.add_graph_documents(
    graph_documents,
    include_source=True,
    baseEntityLabel=True,
  )
</code></pre>

<p>```
      - Doing similar in DGraph would require creating a wrapper as it doesn't have out of box integration with Dgraph.</p>
</li>
</ul>
</li>
</ul></div>
  
    <div class="note"><ul>
<li>Wanted to explore and do hands-on in dbt. Here are the findings:</li>
<li>Notes from Data Engineering project <a href="https://www.youtube.com/watch?v=zZVQluYDwYY&amp;t=5725s">DBT DE Project with Snowflake</a><ul>
<li>DBT doesn't extract or load data. It focuses on transformation step in ETL.</li>
<li>DBT works on top of Data Warehouse. Compute happens in the DW.</li>
<li>I still wonder, I can have .sql in my source code repo and control using that, why dbt then?</li>
<li>Benefits - Documentation out of box | Reusability | Testing Framework built-in | Dependency management | Modular</li>
<li>DBT Cloud vs DBT Core</li>
<li>DBT Core doesn't include built-in semantic layer. It can be done via MetricFlow but expose via api is only feature of cloud.</li>
<li>Cube.dev -&gt; Is an alternative, if one want to stick to dbt core for semantic layer.</li>
</ul>
</li>
<li>DBT markdown notes - <a href="https://publish.obsidian.md/datavidhya/Course+Notes/Dbt(databuildtool)/1.+Introduction+to+DBT">Link here</a></li>
<li>DBT Models<ul>
<li>SQL Scripts are written here. Can reference other models.
<code>shell
dbt run</code></li>
<li><a href="https://docs.getdbt.com/docs/build/materializations">DBT Materialisation</a> for each folder. Supports - table | view | incremental | ephemeral</li>
<li>For incremental, you need to write the logic<ul>
<li>{% if is_incremental() %}</li>
</ul>
</li>
<li>For ephemeral, it's more like creating table in memory, it doesn't get created in warehouse, however, you can still reference it.</li>
<li>Look in dbt_project.yml -&gt; Overwrite possible with config {{ }} in the model sql files</li>
</ul>
</li>
<li>DBT Seed - Not really helpful for large data. It can be used for smaller dataset.</li>
<li>DBT Sources - Helpful for documentation<ul>
<li>Create sources.yml under models/</li>
</ul>
</li>
<li>DBT Snapshots<ul>
<li>Built in implementation of type-2 scd.</li>
<li>There are dbt packages, which are like reusable functions.</li>
<li>Very useful, if one needs SCD in their data warehouse.</li>
</ul>
</li>
<li>DBT Test<ul>
<li>Generic Test - Define in the models/schema.yaml file</li>
<li>Singular Test - Custom sql -&gt; tests/check_custom_business_logic.sql</li>
<li>Test Config - Severity - warn, error -&gt; Things like this can be defined.</li>
</ul>
</li>
<li>DBT Document<ul>
<li>Powerful feature, out of box available in cloud
  <code>bash
  dbt docs generate
  dbt docs serve</code></li>
<li>Lot of features and customisation. Loved it. Lineage is very good.</li>
</ul>
</li>
<li>DBT Macros<ul>
<li>It is more like function. Reuse!</li>
</ul>
</li>
<li>Hooks<ul>
<li>Can be used for logging operation</li>
<li>Maybe access permissions you want to give during start of job &amp; stop at end.</li>
</ul>
</li>
<li>Operation Tasks<ul>
<li>We can create custom operation by defining a macro Ex - Add partition at specific time</li>
</ul>
</li>
<li>CICD should be setup in the repo.</li>
<li>Airflow can be used to trigger models based on schedule.</li>
<li>Model Organisation &amp; naming convention would be very critical here. Inspiration can be taken from <a href="https://publish.obsidian.md/datavidhya/Course+Notes/Dbt(databuildtool)/14.+Advance+DBT+Concept#Project+Organization">here</a></li>
</ul></div>
  
    <div class="note"><ul>
<li>DBT Cloud alternative for semantic layer, if one wants to use dbt-core - cube.dev</li>
<li>https://cube.dev/docs/product/data-modeling/recipes/dbt</li>
<li>Flowershow - Hosting markdown directly as website/blog from Github</li>
<li>https://github.com/flowershow/flowershow/tree/self-hosted-archive</li>
</ul></div>
  
    <div class="note"><ul>
<li>Reading the book - The snowball. Here are some concepts worth noting:</li>
<li>Concept of "Inner Scorecard" vs. "Outer Scorecard" emerged: live by your own values, not society’s expectations.</li>
<li>Ben Graham - Need to read again - The Intelligent Investor.</li>
<li>Value Investion - Buying chepaer than the intrensic value.</li>
</ul></div>
  
    <div class="note"><ul>
<li>Learnt about gihub pages &amp; hosting static websites in it.</li>
<li>Created a webpage https://lokeshnanda.github.io/wl/ where I would publish my daily notes.</li>
<li>Identified the easiest and most economical way to create a domain would be using <a href="https://www.cloudflare.com/">Cloudflair domain</a></li>
</ul></div>
  
    <div class="note"><ul>
<li>Notes from AWS Sumit India 2025</li>
<li>Gen AI<ul>
<li>Where amazon actually used in production genai internally? - chatbot | Audio, video &amp; image generator tool | Inventory management</li>
<li>Amazon Q Developer</li>
<li>Very similar to Cursor, Copilot.</li>
<li>Amazon Q Business</li>
<li>Out of box chatbot, on top of your internal data.</li>
<li>It can integrate with sharepoint. We did this similar in Microsoft Copilot, but observed the cost to be really high for indexing of the documents.<ul>
<li>Need to check on the cost side, how different it is.</li>
</ul>
</li>
<li>Amazon developed AI Chips to help on cost reduction - AWS Trainium2 and Inferentia2.</li>
<li>AWS Bedrock Agents:</li>
<li>Simple multi agent flow use-case without coding can be done here. It points to a knowledge base.</li>
<li>For tools, it allows access to Lambda functions.</li>
<li>AWS Sagemaker - Hyperpod - Fine tuning of LLM's. Hardware support.</li>
<li>Reserved Capacity - 6months - Observed 68% cost reduction.</li>
<li>Slurm(Simple Linux Utility for Resource Manager) - Open Source orchestrator &amp; cluster management system for linux based.</li>
<li>Peplexity AI | Stabality AI use Hyperpod for their training.</li>
<li>Storage</li>
<li>Amazon FSx for Lustre</li>
</ul>
</li>
<li>Data<ul>
<li>Amazon is going the Azure way of Fabric, by introducing Amazon Sagemaker Unified Studio (All in one plarform). Rebrand &amp; name change! Iceberg format native.</li>
<li>But supports all 3 - Hudi, Delta &amp; Iceberg.</li>
<li>Zero-ETL Integration - Federated Querying.</li>
<li>Valkey on Amazon - In-memeory Database</li>
<li>Amazon Elasticache (Serverless option also) - Microsecond write</li>
<li>Amazon Memory DB (In memory with durability) - milli-second write coz data commiteed to multi AZ transaction log. - (Instance based.)<ul>
<li>Free tier available for small workload.</li>
</ul>
</li>
<li>Valkey - Community replacement of Redis, since 7.2, it was not under open-source license.</li>
<li>Bedrock can be directly called in a SQL query for redshift. Directly create a sentiment score with just query. No need of Python etc. Good use-case.</li>
<li>Zero-etl supported for Salesforce via Glue ETL. No need of creating a ingestion framework for this. Auto incremental setups available.</li>
<li>Amazon s3 Table buckets - namespaces - tables</li>
<li>Amazon S3 tables with Amazon Sagemaker Lakehouse.</li>
<li>Auto handling of compaction | snapshots | file-cleaning</li>
<li>Good support for Iceberg using Amazon Kinesis Data Streams &amp; data firehose stream for ingestion to S3 Tables. (Transform using lambda)</li>
<li>Query using Athena and can modify realtime.</li>
<li>Amazon Quicksight - Good Integration with Amazon Q for out of box dashboard creations.</li>
</ul>
</li>
</ul></div>
  
    <div class="note"><ul>
<li>(Use-case in security space)[https://www.zenml.io/llmops-database/optimizing-security-threat-investigation-with-multi-model-llm-strategy]</li>
<li>Insurance claim processing - Intersting use-case for Gen AI app.</li>
<li>I observed, if one agent has too many tasks &amp; tools to connect, it gets difficult to maintain the codebase as well it starts hallucinating. Mutil-agent architecture helps.</li>
</ul></div>
  
    <div class="note"><ul>
<li>Model distillation is a process where a smaller, more efficient model (student) learns to mimic a larger, more powerful model (teacher)</li>
<li>Reduced cost.</li>
</ul></div>
  

  <nav>
    
      <a href="2025-06-22.html">← Previous Week</a>
    

    <a href="index.html" class="nav-home">Home</a>

    
      <span></span>
    
  </nav>
</body>
</html>